{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zFPBYd-zD6tW",
   "metadata": {
    "id": "zFPBYd-zD6tW"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import math\n",
    "import urllib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Adc6XyD4rzgp",
   "metadata": {
    "id": "Adc6XyD4rzgp"
   },
   "source": [
    "# Useful functions\n",
    "- load()\n",
    "- distance_from_rotor(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N1HJg2pwYRsK",
   "metadata": {
    "id": "N1HJg2pwYRsK"
   },
   "outputs": [],
   "source": [
    "def load():\n",
    "    \n",
    "    \"\"\" Load the trajectories X_1.csv, Y_1.csv and the two directional\n",
    "        aerodynamic forces FX_1.csv and FY_1.csv.\n",
    "        It translates these files into np.ndarray variables of shape (N, T)\n",
    "        where N = number of trajectories (int) and T = time steps (int) \"\"\"\n",
    "   \n",
    "   \n",
    "    X = np.genfromtxt(\"X_1.csv\", delimiter=\",\")\n",
    "    Y = np.genfromtxt(\"Y_1.csv\", delimiter=\",\")\n",
    "    Fx = np.genfromtxt(\"FX_1.csv\", delimiter=\",\")\n",
    "    Fy = np.genfromtxt(\"FY_1.csv\", delimiter=\",\")\n",
    "    \n",
    "    \n",
    "    return X.T, Y.T, Fx.T, Fy.T\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def distance_from_rotor(X, Y):\n",
    "    \n",
    "    \"\"\" Given the two datasets containing the coordinates of all the trajectory,\n",
    "        it computes a new variable np.ndarray (N, T) containing, for all the \n",
    "        trajectories and for every time instant, the clearance parameter (i.e.\n",
    "        the distance of the center of mass of the rotor from the bearing)\n",
    "        \n",
    "        Input: X = shape(N, T), float\n",
    "               Y = shape(N, T), float\n",
    "               \n",
    "        Output: R-r = shape(N, T), float \"\"\"\n",
    "    \n",
    "    R = 0.5\n",
    "    r = np.sqrt(X**2 + Y**2)\n",
    "    return R - r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f193d25",
   "metadata": {},
   "source": [
    "# Loading of the dataset\n",
    "- over 500 trajectories, the first 50 (10%) are taken as testing set, 400 (90%) are used as training set and the remaining 50 (10%) are the validation set used duering the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16JOK4PgRSe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "b16JOK4PgRSe",
    "outputId": "369d1914-02ba-48dd-da26-68e6a6106cf8"
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "X, Y, Fx, Fy = load()\n",
    "\n",
    "# take the first 50 trajectories (10%) that will be eventually tested\n",
    "X_to_test = X[:50, :]\n",
    "Y_to_test = Y[:50, :]\n",
    "Fx_to_test = Fx[:50, :]\n",
    "Fy_to_test = Fy[:50, :]\n",
    "dist_to_test = distance_from_rotor(X_to_test, Y_to_test)\n",
    "\n",
    "# take the rest of the trajectories (90%) to train and validate the model\n",
    "X = X[50:, :]\n",
    "Y = Y[50:, :]\n",
    "Fx = Fx[50:, :]\n",
    "Fy = Fy[50:, :]\n",
    "\n",
    "N = X.shape[0]\n",
    "D = X.shape[1]\n",
    "dist = distance_from_rotor(X, Y)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c99ba84",
   "metadata": {},
   "source": [
    "# Useful functions for the creation of the dataset for FNNs\n",
    "\n",
    "Functions:\n",
    "- create_dataset_5feat\n",
    "- create_dataset_5feat_onetraj\n",
    "- random_permutation\n",
    "- tensorize\n",
    "- split_train_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UrxVhnEEgfz2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UrxVhnEEgfz2",
    "outputId": "a923bb3a-070b-4a60-d811-df0ffcddcfb0"
   },
   "outputs": [],
   "source": [
    "def create_dataset_5feat(N, D, dd, X, Y, dist, Fx, Fy):\n",
    "    \n",
    "    \"\"\" This function creates a dataset that, for each observation (i.e. row),\n",
    "        contains the X and Y coordinates, the clearance parameter and the (x,y) coordinates of the forces (respectively named Fx,Fy) of the dd \n",
    "        time steps prior to the time instant t the observation itself refers to.\n",
    "        To be more clear, the dimensions of the input and the output of the funztion are:\n",
    "        \n",
    "        Input: N = scalar, int (Number of trajectories)\n",
    "               D = scalar, int (Number of overall time steps)\n",
    "               d = scalar, int (Delay parameter)\n",
    "               X = shape(N, T), float (X coordinates of all the trajectories)\n",
    "               Y = shape(N, T), float (Y coordinates of all the trajectories)\n",
    "               dist = shape(N, T), float (Clearance of all the trajectories)\n",
    "               Fx = shape(N, T), float (Aerodynamic forces along x of all the trajectories)\n",
    "               Fy = shape(N, T), float (Aerodynamic forces along y of all the trajectories)\n",
    "        \n",
    "        Output: df_input = shape(N*(D-dd), dd*5), float (Reorganized input dataset of all the trajectories)\n",
    "                df_output = shape(N*(D-dd), 2), float (Reorganized output dataset of all the trajectories) \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_input = np.zeros((N*(D-dd), dd*5))\n",
    "    df_output = np.zeros((N*(D-dd), 2))\n",
    "    i = 0\n",
    "\n",
    "    for t in range(N):\n",
    "    \n",
    "        for n in range(D-dd):\n",
    "\n",
    "            row = np.zeros(dd*5)\n",
    "\n",
    "            for d in range(dd):\n",
    "            \n",
    "                row[5*d] = X[t, n+d]\n",
    "                row[5*d + 1] = Y[t, n+d]\n",
    "                row[5*d + 2] = dist[t, n+d]\n",
    "                row[5*d + 3] = Fx[t, n+d]\n",
    "                row[5*d + 4] = Fy[t, n+d]\n",
    "        \n",
    "            df_input[i, :] = row\n",
    "            df_output[i, :] = np.array([Fx[t, n+dd], Fy[t, n+dd]])\n",
    "            i = i+1\n",
    "    \n",
    "    return df_input, df_output\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "def create_dataset_5feat_onetraj(D, dd, X, Y, dist, Fx, Fy):\n",
    "    \n",
    "    \"\"\" This function creates a dataset that, for each observation (i.e. row),\n",
    "        contains the X and Y coordinates, the clearance parameter and the (x,y) coordinates of the forces (respectively named Fx,Fy) of the dd \n",
    "        time steps prior to the time instant t the observation itself refers to.\n",
    "        In particular, this is done for just one trajectory (and not for all the \n",
    "        trajectories as the function above)\n",
    "        \n",
    "        Input: D = scalar, int (Number of overall time steps)\n",
    "               d = scalar, int (Delay parameter)\n",
    "               X = shape(T, ), float (X coordinates of the given trajectory)\n",
    "               Y = shape(T, ), float (Y coordinates of the given trajectory)\n",
    "               dist = shape(T, ), float (Clearance of the given trajectory)\n",
    "               Fx = shape(T, ), float (Aerodynamic forces along x of the given trajectory)\n",
    "               Fy = shape(T, ), float (Aerodynamic forces along y of the given trajectory)\n",
    "        \n",
    "        Output: df_input = shape(D-dd, dd*5), float (Reorganized input dataset of the given trajectory)\n",
    "                df_output = shape(D-dd, 2), float (Reorganized output dataset of the given trajectory) \"\"\"\n",
    "    \n",
    "    \n",
    "    df_input = np.zeros((D-dd, dd*5))\n",
    "    df_output = np.zeros((D-dd, 2))\n",
    "    i = 0\n",
    "\n",
    "    for n in range(D-dd):\n",
    "        \n",
    "        row = np.zeros(dd*5)\n",
    "\n",
    "        for d in range(dd):\n",
    "            \n",
    "            row[5*d] = X[n+d]\n",
    "            row[5*d + 1] = Y[n+d]\n",
    "            row[5*d + 2] = dist[n+d]\n",
    "            row[5*d + 3] = Fx[n+d]\n",
    "            row[5*d + 4] = Fy[n+d]\n",
    "        \n",
    "        df_input[i, :] = row\n",
    "        df_output[i, :] = np.array([Fx[n+dd], Fy[n+dd]])\n",
    "        i = i+1\n",
    "    \n",
    "    return df_input, df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GToeuoxyYWS9",
   "metadata": {
    "id": "GToeuoxyYWS9"
   },
   "outputs": [],
   "source": [
    "def random_permutation(df_input, df_output):\n",
    "    \n",
    "    \"\"\" Random permutation of the observations (i.e. rows) of the\n",
    "        input and output dataset.\n",
    "        R = number of rows and C = number of columns of the input\n",
    "        \n",
    "        Input: df_input = shape(R, C), float (Input dataset)\n",
    "               df_output = shape(R, 2), float (Output output)\n",
    "        \n",
    "        Output: df_in_shuff = shape(R, C), float (Shuffled input dataset)\n",
    "                df_out_shuff = shape(R, 2), float (Shuffled output dataset) \"\"\"\n",
    "    \n",
    "\n",
    "    N = df_input.shape[0]\n",
    "    shuffle_indices = np.random.permutation(np.arange(N))\n",
    "    df_in_shuff = df_input[shuffle_indices]\n",
    "    df_out_shuff = df_output[shuffle_indices]\n",
    "\n",
    "    return df_in_shuff, df_out_shuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eiBREjBvYaIb",
   "metadata": {
    "id": "eiBREjBvYaIb"
   },
   "outputs": [],
   "source": [
    "def tensorize(df_in_shuff, df_out_shuff):\n",
    "    \n",
    "    \"\"\" Transform a np.ndarray into a torch.Tensor variable.\n",
    "        R = number of rows and C = number of columns of the input\n",
    "        \n",
    "        Input: df_in_shuff = shape(R, C), float (Input np.ndarray)\n",
    "               df_out_shuff = shape(R, 2), float (Output np.ndarray)\n",
    "        \n",
    "        Output: df_input_tensor = shape(R, C), float (Input torch.Tensor)\n",
    "                df_output_tensor = shape(R, 2), float (Output torch.Tensor) \"\"\"\n",
    "    \n",
    "\n",
    "    df_input_tensor = torch.Tensor(df_in_shuff)\n",
    "    df_output_tensor = torch.Tensor(df_out_shuff)\n",
    "\n",
    "    return df_input_tensor, df_output_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HRcE8zd2YddK",
   "metadata": {
    "id": "HRcE8zd2YddK"
   },
   "outputs": [],
   "source": [
    "def split_train_val(df_input_tensor, df_output_tensor, p):\n",
    "    \n",
    "    \"\"\" Split the input dataset and the output dataset into a fraction p\n",
    "        of training set and 1-p of validation test. \n",
    "        In particular the first (100*p)% of samples are taken as training\n",
    "        and the remaining 100*(1-p)% of them is the validation set.\n",
    "        R = number of rows and C = number of columns of the input\n",
    "        \n",
    "        Input: df_input_tensor = shape(R, C), float (Input torch.Tensor)\n",
    "               df_output_tensor = shape(R, 2), float (Output torch.Tensor)\n",
    "        \n",
    "        Output: df_in_valid = shape(int(R*(1-p)), C), float (Input Validation Set torch.Tensor)\n",
    "                df_out_valid = shape(int(R*(1-p)), 2), float (Output Validation Set torch.Tensor)\n",
    "                df_in_train = shape(int(R*p), C), float (Input Training Set torch.Tensor)\n",
    "                df_out_train = shape(int(R*p), 2), float (Output Training Set torch.Tensor) \"\"\"\n",
    "  \n",
    "  \n",
    "    # Take the first p% of the dataset as training set and (1-p)% as validation set\n",
    "    N = df_input_tensor.shape[0]\n",
    "    df_in_train = df_input_tensor[:int(N*p), :]\n",
    "    df_in_valid = df_input_tensor[int(N*p):, :]\n",
    "\n",
    "    df_out_train = df_output_tensor[:int(N*p), :]\n",
    "    df_out_valid = df_output_tensor[int(N*p):, :]\n",
    "\n",
    "    return df_in_train, df_in_valid, df_out_train, df_out_valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be4832e",
   "metadata": {},
   "source": [
    "# Creation of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65GHSkouYiuU",
   "metadata": {
    "id": "65GHSkouYiuU"
   },
   "outputs": [],
   "source": [
    "dd = 100\n",
    "p = 0.9\n",
    "\n",
    "df_input, df_output = create_dataset_5feat(N, D, dd, X, Y, dist, Fx, Fy)\n",
    "df_in_shuff, df_out_shuff = random_permutation(df_input, df_output)\n",
    "df_input_tensor, df_output_tensor = tensorize(df_in_shuff, df_out_shuff)\n",
    "df_in_train, df_in_valid, df_out_train, df_out_valid = split_train_val(df_input_tensor, df_output_tensor, p)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(df_in_train, df_out_train)\n",
    "test = torch.utils.data.TensorDataset(df_in_valid, df_out_valid) #VALIDATION\n",
    "\n",
    "# Didn't change name not to change everything afterwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa41a112",
   "metadata": {},
   "source": [
    "# Definition of the Feedforward Neural Network\n",
    "Architecture: \n",
    "- 3 hidden fully connected layers ('hidden1', 'hidden2' and 'hidden3' neurons, respectively).\n",
    "- Activation function: ReLu for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ls1duEK3YpQ7",
   "metadata": {
    "id": "Ls1duEK3YpQ7"
   },
   "outputs": [],
   "source": [
    "class Aerospace_Bearing_FNN(torch.nn.Module):\n",
    "    # Models in PyTorch usually inherit from this Module\n",
    "    def __init__(self, feat, d, hidden1, hidden2, hidden3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_layer = torch.nn.Linear(feat*d, hidden1)\n",
    "        self.input_phi = torch.nn.ReLU()\n",
    "        self.layer1 = torch.nn.Linear(hidden1, hidden2)\n",
    "        self.phi1 = torch.nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(hidden2, hidden3)\n",
    "        self.phi2 = torch.nn.ReLU()\n",
    "        self.output_layer = torch.nn.Linear(hidden3, 2)\n",
    "\n",
    "    def forward(self, Z):\n",
    "        # Z = torch.flatten(Z, 1)  # Flatten (n, 28, 28) to (n, 784)\n",
    "        Z = self.input_layer(Z)\n",
    "        Z = self.input_phi(Z)\n",
    "        Z = self.layer1(Z)\n",
    "        Z = self.phi1(Z)\n",
    "        Z = self.layer2(Z)\n",
    "        Z = self.phi2(Z)\n",
    "        Z = self.output_layer(Z)\n",
    "\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc95797",
   "metadata": {},
   "source": [
    "# Training process\n",
    "- Optimizer: Adam's\n",
    "- Scheduler: CosineAnnealingLR\n",
    "- Criterion: MSE Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biSzRqMbYrie",
   "metadata": {
    "id": "biSzRqMbYrie"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, scheduler, criterion, train_loader, epoch, device):\n",
    "    \n",
    "    # Set model to training mode (affects dropout, batch norm e.g.)\n",
    "    model.train()\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    lr_history = []\n",
    "    \n",
    "    # Change the loop to get batch_idx, data and target from train_loader\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # Move the data to the device\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute model output\n",
    "        output = model(data)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backpropagate loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform an optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Perform a learning rate scheduler step\n",
    "        scheduler.step()\n",
    "\n",
    "        # Compute loss_float (float value, not a tensor)\n",
    "        loss_float = loss.item()\n",
    "\n",
    "        # Add loss_float to loss_history\n",
    "        loss_history.append(loss_float)\n",
    "\n",
    "        lr_history.append(scheduler.get_last_lr()[0])\n",
    "        if batch_idx % (len(train_loader.dataset) // len(data) // 10) == 0:\n",
    "            print(\n",
    "                f\"Train Epoch: {epoch}-{batch_idx:03d} \"\n",
    "                f\"batch_loss={loss_float:0.2e} \"\n",
    "                # f\"batch_acc={accuracy_float:0.3f} \"\n",
    "                f\"lr={scheduler.get_last_lr()[0]:0.3e} \"\n",
    "            )\n",
    "\n",
    "    return loss_history, lr_history\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, device, val_loader, criterion):\n",
    "    model.eval()  # Important: eval mode (affects dropout, batch norm etc)\n",
    "    test_loss = 0\n",
    "    \n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item() * len(data)\n",
    "        \n",
    "    test_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"Test set: Average loss: {:.4f}\".format(test_loss)\n",
    "    )\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_predictions(model, device, val_loader, criterion, num=None):\n",
    "    model.eval()\n",
    "    points = []\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        data = np.split(data.cpu().numpy(), len(data))\n",
    "        loss = np.split(loss.cpu().numpy(), len(data))\n",
    "        target = np.split(target.cpu().numpy(), len(data))\n",
    "        \n",
    "        points.extend(zip(data, loss, target))\n",
    "\n",
    "        if num is not None and len(points) > num:\n",
    "            break\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def run_aerobearing_training(feat, ddd, hidden1, hidden2, hidden3, num_epochs, lr, batch_size, device=\"cpu\"):\n",
    "    # ===== Data Loading =====\n",
    "    transform = transforms.ToTensor()\n",
    "    train_set = train\n",
    "    val_set = test\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # Can be important for training\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        drop_last=False,\n",
    "        num_workers=2,\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    # ===== Model, Optimizer and Criterion =====\n",
    "\n",
    "    model = Aerospace_Bearing_FNN(feat, ddd, hidden1, hidden2, hidden3)\n",
    "    model = model.to(device=device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    criterion = torch.nn.functional.mse_loss\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader.dataset) * num_epochs) // train_loader.batch_size)\n",
    "    \n",
    "    # ===== Train Model =====\n",
    "    lr_history = []\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, lrs = train_epoch(model, optimizer, scheduler, criterion, train_loader, epoch, device)\n",
    "        train_loss_history.extend(train_loss)\n",
    "        lr_history.extend(lrs)\n",
    "\n",
    "        val_loss = validate(model, device, val_loader, criterion)\n",
    "        val_loss_history.append(val_loss)\n",
    "        \n",
    "    # ===== Plot training curves =====\n",
    "    n_train = len(train_loss_history)\n",
    "    t_train = num_epochs * np.arange(n_train) / n_train\n",
    "    t_val = np.arange(1, num_epochs + 1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t_train, train_loss_history, label=\"Train\")\n",
    "    plt.plot(t_val, val_loss_history, label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(t_train, lr_history)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Learning Rate\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa289289",
   "metadata": {},
   "source": [
    "# Set-up of the parameters\n",
    "\n",
    "The parameters which characterize the model are the following:\n",
    "- The learning rate and the number of hidden layers which were obtained from the file `FNN_predicted_tuning` (respectively `lr`, `hidden1`, `hidden2`, `hidden3`)\n",
    "- The size of the bacth and number of epochs (`batch_size`, `num_epochs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RZJCXhbkYu3Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "RZJCXhbkYu3Z",
    "outputId": "0edd93cf-f755-41c4-c8a3-8076b53a9cb8"
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "batch_size = 500\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "feat = 5\n",
    "hidden1 = 256\n",
    "hidden2 = 256\n",
    "hidden3 = 64\n",
    "\n",
    "model = run_aerobearing_training(feat, dd, hidden1, hidden2, hidden3, num_epochs, lr, batch_size, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7dc26d",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z2Y0YZXsYzCn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2Y0YZXsYzCn",
    "outputId": "f968374b-d9a1-464b-ebe0-5519c05433fe"
   },
   "outputs": [],
   "source": [
    "def get_mse_re_5feat(tbp_Fx, tbp_Fy, tbp_X, tbp_Y, tbp_d, D, dd, model):\n",
    "    \n",
    "    \"\"\" It computes the MSE (Mean Square Error) and the Relative Error (Absolute Error / Magnitude of the Output)\n",
    "        between the prediction of the model and the true value of the output.\n",
    "        This function first computes the (dd+1)th prediction\n",
    "        of the forces given the previous dd observations of Fx, Fy, X, Y and \n",
    "        clearance. Then, the computation of the (dd+2)th forces (Fx,Fy) will be \n",
    "        based on the (dd+1)th predicted forces (Fx, Fy) from the previous computation\n",
    "        and the [1:dd] forces (true forces), as well as the previous dd observations of X, Y and \n",
    "        clearance. From the (dd) th iteration untill the last, the model\n",
    "        will use only the predicted forces as input.\n",
    "        \n",
    "        Once all the predicted forces are computed, the MSE wrt to the\n",
    "        actual value of the forces is computed and averaged over the two \n",
    "        directions: this is the error taken for a single observation.\n",
    "        Then the mean over all samples is returned.\n",
    "        R = number of rows and C = number of columns of the input\n",
    "        \n",
    "        Input: tbp_X = X[:50, :]\n",
    "               tbp_Y = Y[:50, :]\n",
    "               tbp_Fx = Fx[:50, :]\n",
    "               tbp_Fy = Fy[:50, :]\n",
    "               tbp_d = distance_from_rotor(tbp_X, tbp_Y)\n",
    "               D = scalar, int (Number of overall time steps)\n",
    "               dd = scalar, int (Delay parameter)\n",
    "               model = Output of run_aerobearing_training\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    mse_vec=list()\n",
    "    re_vec=list()\n",
    "    \n",
    "    for m in range(len(tbp_Fx)):\n",
    "        my_Fx = tbp_Fx[m,:].copy()\n",
    "        my_Fy = tbp_Fy[m,:].copy()\n",
    "        df_tbp = np.zeros((D-dd,dd*5))\n",
    "        df_tbp_out = np.zeros((D-dd,2))\n",
    "            \n",
    "        row = np.zeros(dd*5)\n",
    "    \n",
    "        for d in range(dd):        \n",
    "            row[5*d] = tbp_X[m,d]\n",
    "            row[5*d + 1] = tbp_Y[m,d]\n",
    "            row[5*d + 2] = tbp_d[m,d]\n",
    "            row[5*d + 3] = tbp_Fx[m,d]\n",
    "            row[5*d + 4] = tbp_Fy[m,d]\n",
    "    \n",
    "        df_tbp[0, :] = row        \n",
    "        i=1\n",
    "        pred_vec = list()\n",
    "        \n",
    "        for n in (np.arange(1,D-dd)):\n",
    "        \n",
    "        \n",
    "            row = np.zeros(dd*5)\n",
    "        \n",
    "            inp = torch.Tensor(df_tbp[i-1,:])\n",
    "            inp = torch.unsqueeze(inp,0)\n",
    "            inp = inp.to(device)\n",
    "            pred = model(inp)\n",
    "            pred = pred.to(\"cpu\")\n",
    "            pred_vec.append( [float(pred[0][0]), float(pred[0][1])])\n",
    "            my_Fx[n+dd-1] = float(pred[0][0])\n",
    "            my_Fy[n+dd-1] = float(pred[0][1])\n",
    "        \n",
    "            for d in range(dd):\n",
    "                row[5*d] = tbp_X[m,n+d]\n",
    "                row[5*d + 1] = tbp_Y[m,n+d]\n",
    "                row[5*d + 2] = tbp_d[m,n+d]\n",
    "                row[5*d + 3] = my_Fx[n+d]\n",
    "                row[5*d + 4] = my_Fy[n+d]\n",
    "        \n",
    "            df_tbp[i, :] = row\n",
    "            df_tbp_out[i, :] = np.array([tbp_Fx[m,n+dd], tbp_Fy[m,n+dd]])\n",
    "            i=i+1\n",
    "            \n",
    "        pred_vec = np.array(pred_vec)\n",
    "        mse_vec.append((np.mean((pred_vec[:,:]-df_tbp_out[1:,:])**2)))\n",
    "        re_vec.append(np.mean(np.abs((df_tbp_out[1:,:] - pred_vec[:,:])/df_tbp_out[1:,:])))\n",
    "        \n",
    "    return np.mean(mse_vec), np.mean(re_vec), pred_vec, df_tbp_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bZVUlScz_O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11bZVUlScz_O",
    "outputId": "5c74f103-a8a8-4ee1-ef8d-07a62688c9ad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse_d,re_d, pred_vec, df_tbp_out = get_mse_re_5feat(Fx_to_test, Fy_to_test, X_to_test, Y_to_test, dist_to_test, D, dd, model)\n",
    "print(mse_d)\n",
    "print(re_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b648fc",
   "metadata": {},
   "source": [
    "# Plot of a given trajectory of aerodynamic forces and its prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 50th trajectory\n",
    "pred_vec = np.array(pred_vec)\n",
    "\n",
    "plt.plot(pred_vec[1:,0], pred_vec[1:,1],label=\"Pred\")\n",
    "plt.plot(df_tbp_out[1:,0], df_tbp_out[1:,1],label=\"True\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9103baa99c45b333c620567d69faf1aa799e372ff7d98bf9af9f12991e0ec50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
